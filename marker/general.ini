# This is a config file with the shared settings for crop classification 

[general]
environment = DEV

# File format (extension) to use for data that is best saved in a column-optimized way
columndata_ext = .parquet
# File format (extension) to use for data that is best saved in a row-optimized way
rowdata_ext = .parquet
# File format (extension) to use for data that is output data (should be easy to use)
output_ext = .tsv

# Constants for types of aggregation to use
# Mean value of the pixels values in a parcel.
PARCELDATA_AGGRAGATION_MEAN = mean
# std dev of the values of the pixels in a parcel
PARCELDATA_AGGRAGATION_STDDEV = stdDev

# Constants for types of sensor data
SENSORDATA_S1 = S1
# Sentinel 1 data
# Sentinel 1 data, in dB
SENSORDATA_S1DB = S1dB
# Sentinel 1 data, divided in Ascending and Descending passes
SENSORDATA_S1_ASCDESC = S1AscDesc
# Sentinel 1 data, in dB, divided in Ascending and Descending passes
SENSORDATA_S1DB_ASCDESC = S1dBAscDesc
# Sentinel 2 data
SENSORDATA_S2 = S2
# Sentinel 2 data (B2,B3,B4,B8) IF available for 95% or area
SENSORDATA_S2gt95 = S2gt95

[marker]
# The region of the classification: typically country code
country_code = BEFL
# year to run
year = 2018
# markertype, must be overriden in child ini files
markertype = MUST_OVERRIDE
# 
input_classtype_to_prepare = ${markertype}
input_classtype_to_prepare_groundtruth = ${markertype}_GROUNDTRUTH
# start date timeseries data (note, nearest monday will be used)
start_date_str = ${year}-03-27 
# end date timeseries data (note: end date is NOT inclusive for gee processing)
end_date_str = ${year}-08-10
# negative buffer to apply to input parcels
buffer = 10
# minimum number of pixels that should be inside the buffered input parcels
min_nb_pixels = 10
# classes that should be ignored for training, but do have to get a prediction
classes_to_ignore_for_train = UNKNOWN, MON_LC_UNKNOWN
# classes that will be ignored for training and won't receive a prediction either
classes_to_ignore = IGNORE_DIFFICULT_PERMANENT_CLASS, IGNORE_UNIMPORTANT_CLASS,MON_LC_IGNORE_DIFFICULT_PERMANENT_CLASS, MON_LC_IGNORE_DIFFICULT_PERMANENT_CLASS_NS, MON_LC_INELIGIBLE

# strategy to balance the training dataset for the marker. Possible values:
#   * BALANCING_STRATEGY_NONE: don't apply any balancing: 20% of the input samples per class is used for training
#   * BALANCING_STRATEGY_UPPER_LIMIT: 80% of input data is used for training, with a maximum of 10.000 samples per class
#   * BALANCING_STRATEGY_MEDIUM: 80% of input data is used for training, with maximum 10.000 samples per class and minimum 1.000 (samples will be duplicated if needed)
#   * BALANCING_STRATEGY_EQUAL: for each input class, the same amount of samples is used as training. For classes with few samples, (samples will be duplicated if needed)
balancing_strategy = BALANCING_STRATEGY_MEDIUM

# Is there a reclassification necessary as postprocessing step 
postprocess_reclassify = False

# The sensor data to be used for this marker
sensordata_to_use = ${general:SENSORDATA_S1_ASCDESC}, ${general:SENSORDATA_S2gt95}
# The aggregation type to use on parcel level
parceldata_aggregations_to_use = ${general:PARCELDATA_AGGRAGATION_MEAN}

[marker:2017]
input_parcel_filename_noext = Prc_flanders_2017_2018-01-09
input_groundtruth_filepath = Prc_BEFL_2017_groundtruth.csv

[marker:2018]
#input_parcel_filename_noext = Prc_BEFL_2018_2018-08-02
input_parcel_filename_noext = Prc_BEFL_2018_2019-05-02
input_groundtruth_filepath = Prc_BEFL_2018_groundtruth.csv

[preprocess]
dedicated_data_columns = ${columns:id}, ${columns:class}, ${columns:class_orig}, ${columns:is_eligible}, ${columns:is_permanent}, ${columns:pixcount_s1s2}
extra_export_columns = CODE_OBJ, LAYER_ID, PRC_ID, VERSIENR, GWSCOD_H

[classifier]
type = multi_layer_perceptron
hidden_layer_sizes = 100
max_iter = 200

[columns]
# Column name of the id column
id = UID
# Column name of the geom column
geom = geometry
# Column name of the class, after preprocessing to optimize the classification
class = classname
# Column name of the original class of the parcel, before additional preprocessing
class_orig = classname_orig
# Column name of the class to use for balancing the training dataset
class_balancing = ${class}
# Column that is 1 for parcels with an eligible crop, 0 for ineligible crop/landcover
is_eligible = is_eligible
# Column that is 1 for parcels with a permanent landcover, 0 for a regular crop. Permanent landcovers can/should be followed up in the LPIS upkeep
is_permanent = is_permanent
# Column name of the count of the number of pixels for sentinel1/2 images
pixcount_s1s2 = pixcount
# Column name of the standard prediction (probability can be same as other classes)
prediction = pred1
# Column name of the prediction with doubt (so has a minimum probability)
prediction_withdoubt = pred_withdoubt
# Column name of the consolidated prediction: can be doubt, not_enough_pixels,...
prediction_cons = pred_consolidated
# Column name of the detailed conclusion based on standard prediction
prediction_conclusion_detail = pred_conclusion_detail
# Column name of the detailed conclusion based on prediction with doubt
prediction_conclusion_detail_withdoubt = pred_conclusion_detail_withdoubt
# Column name of the detailed conclusion based on consolidated prediction
prediction_conclusion_detail_cons = pred_conclusion_detail_cons
# Column name of the conclusion based on consolidated prediction
prediction_conclusion_cons = pred_conclusion_cons
# The status/result of the prediction
prediction_status = pred_status

[dirs]
reuse_last_run_dir = False
root_dir = X:\monitoring\markers
environment_dir = ${dirs:root_dir}\${general:environment}
base_dir = ${dirs:environment_dir}
imagedata_dir = ${dirs:environment_dir}\_timeseries_data
marker_base_dir = ${dirs:base_dir}\${marker:year}_${marker:markertype}
input_dir = ${dirs:base_dir}\inputdata
input_preprocessed_dir = ${dirs:input_dir}\preprocessed
log_dir = ${dirs:marker_base_dir}\log\
gee = users/pieter_roggemans/
